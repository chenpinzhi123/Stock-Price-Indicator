{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Train the model\n",
    "\n",
    "Using the data created from Step 1, here we are going to build a simple benchmark model (simple neural network) to evaluate the stock return predictability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# default S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data' # the folder we will use for storing data\n",
    "name = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-1-165829362107/stock-price-predictor\n"
     ]
    }
   ],
   "source": [
    "# specify where to upload in S3\n",
    "prefix = 'stock-price-predictor'\n",
    "\n",
    "# upload to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn.functional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mSimpleNet\u001b[39;49;00m(nn.Module):\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_dim, hidden_dim, output_dim):\n",
      "        \u001b[33m'''Defines layers of a neural network.\u001b[39;49;00m\n",
      "\u001b[33m           :param input_dim: Number of input features\u001b[39;49;00m\n",
      "\u001b[33m           :param hidden_dim: Size of hidden layer(s)\u001b[39;49;00m\n",
      "\u001b[33m           :param output_dim: Number of outputs\u001b[39;49;00m\n",
      "\u001b[33m         '''\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(SimpleNet, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "\n",
      "        \u001b[37m# defining 2 linear layers\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(input_dim, hidden_dim)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(hidden_dim, output_dim)\n",
      "        \u001b[36mself\u001b[39;49;00m.drop = nn.Dropout(\u001b[34m0.1\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        \u001b[33m'''Feedforward behavior of the net.\u001b[39;49;00m\n",
      "\u001b[33m           :param x: A batch of input features\u001b[39;49;00m\n",
      "\u001b[33m           :return: A single, sigmoid activated value\u001b[39;49;00m\n",
      "\u001b[33m        '''\u001b[39;49;00m\n",
      "        out = \u001b[36mself\u001b[39;49;00m.fc1(x)\n",
      "        out = \u001b[36mself\u001b[39;49;00m.sig(out)\n",
      "        \u001b[37m# convert to from -1 to 1\u001b[39;49;00m\n",
      "        out = \u001b[34m2\u001b[39;49;00m * out - \u001b[34m1\u001b[39;49;00m\n",
      "        out = \u001b[36mself\u001b[39;49;00m.drop(out)\n",
      "        out = \u001b[36mself\u001b[39;49;00m.fc2(out)\n",
      "        \u001b[34mreturn\u001b[39;49;00m out\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_simpleNet/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function  \u001b[37m# future proof\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# pytorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.optim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.utils.data\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# import model\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SimpleNet\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\n",
      "    model_info = {}\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = torch.load(f)\n",
      "\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\n",
      "\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model = SimpleNet(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33minput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                      model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                      model_info[\u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Load the stored model parameters.\u001b[39;49;00m\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\n",
      "\n",
      "\n",
      "\u001b[37m# Load the training data from a csv file\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_loader\u001b[39;49;00m(batch_size, data_dir):\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet data loader.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# read in csv file\u001b[39;49;00m\n",
      "    train_data = pd.read_csv(os.path.join(data_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[36mNone\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# labels are first column\u001b[39;49;00m\n",
      "    train_y = torch.from_numpy(train_data[[\u001b[34m0\u001b[39;49;00m]].values).float().squeeze()\n",
      "    \u001b[37m# features are the rest\u001b[39;49;00m\n",
      "    train_x = torch.from_numpy(train_data.drop([\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values).float()\n",
      "\n",
      "    \u001b[37m# create dataset\u001b[39;49;00m\n",
      "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
      "\n",
      "\n",
      "\u001b[37m# Provided train function\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model, train_loader, epochs, optimizer, criterion, device):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    This is the training method that is called by the PyTorch training script. The parameters\u001b[39;49;00m\n",
      "\u001b[33m    passed are as follows:\u001b[39;49;00m\n",
      "\u001b[33m    model        - The PyTorch model that we wish to train.\u001b[39;49;00m\n",
      "\u001b[33m    train_loader - The PyTorch DataLoader that should be used during training.\u001b[39;49;00m\n",
      "\u001b[33m    epochs       - The total number of epochs to train for.\u001b[39;49;00m\n",
      "\u001b[33m    optimizer    - The optimizer to use during training.\u001b[39;49;00m\n",
      "\u001b[33m    criterion    - The loss function used for training.\u001b[39;49;00m\n",
      "\u001b[33m    device       - Where the model and data should be loaded (gpu or cpu).\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train()\n",
      "        total_loss = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\n",
      "            \u001b[37m# prep data\u001b[39;49;00m\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            optimizer.zero_grad()  \u001b[37m# zero accumulated gradients\u001b[39;49;00m\n",
      "            \u001b[37m# get output of SimpleNet\u001b[39;49;00m\n",
      "            output = model(data)\n",
      "            \u001b[37m# calculate loss and perform backprop\u001b[39;49;00m\n",
      "            loss = criterion(output, target)\n",
      "            loss.backward(retain_graph=\u001b[36mTrue\u001b[39;49;00m)\n",
      "            \u001b[37m# loss.backward()\u001b[39;49;00m\n",
      "            optimizer.step()\n",
      "\n",
      "            total_loss += loss.item()\n",
      "\n",
      "        \u001b[37m# print loss stats\u001b[39;49;00m\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: {}, Loss: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch, total_loss / \u001b[36mlen\u001b[39;49;00m(train_loader)))\n",
      "\n",
      "    \u001b[37m# save trained model, after all epochs\u001b[39;49;00m\n",
      "    save_model(model, args.model_dir)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[37m# Provided model saving functions\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[37m# save state dictionary\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model_params\u001b[39;49;00m(model, model_dir):\n",
      "    model_info_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = {\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33minput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.input_dim,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.hidden_dim,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.output_dim\n",
      "        }\n",
      "        torch.save(model_info, f)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Training Parameters, given\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.001\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 0.001)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10000\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Model parameters\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--input_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m46\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of input features to model (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mhidden dim of model (default: 20)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mOUT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33moutput dim of model (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.is_available():\n",
      "        torch.cuda.manual_seed(args.seed)\n",
      "\n",
      "    \u001b[37m# get train loader\u001b[39;49;00m\n",
      "    train_loader = _get_train_loader(args.batch_size, args.data_dir)  \u001b[37m# data_dir from above..\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# To get params from the parser, call args.argument_name, ex. args.epochs or ards.hidden_dim\u001b[39;49;00m\n",
      "    \u001b[37m# Don't forget to move your model .to(device) to move to GPU , if appropriate\u001b[39;49;00m\n",
      "    model = SimpleNet(args.input_dim, args.hidden_dim, args.output_dim).to(device)\n",
      "\n",
      "    \u001b[37m# Given: save the parameters used to construct the model\u001b[39;49;00m\n",
      "    save_model_params(model, args.model_dir)\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
      "    criterion = nn.MSELoss()\n",
      "\n",
      "    \u001b[37m# Trains the model (given line of code, which calls the above training function)\u001b[39;49;00m\n",
      "    \u001b[37m# This function *also* saves the model state dictionary\u001b[39;49;00m\n",
      "    train(model, train_loader, args.epochs, optimizer, criterion, device)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_simpleNet/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "# prefix is specified above\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='source_simpleNet', # this should be just \"source\" for your code\n",
    "                    role=role,\n",
    "                    framework_version='1.3.1',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'input_dim': 46,  # num of features\n",
    "                        'hidden_dim': 20,\n",
    "                        'output_dim': 1,\n",
    "                        'epochs': 100 # could change to higher\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-24 02:32:12 Starting - Starting the training job...\n",
      "2020-02-24 02:32:14 Starting - Launching requested ML instances......\n",
      "2020-02-24 02:33:17 Starting - Preparing the instances for training...\n",
      "2020-02-24 02:34:11 Downloading - Downloading input data...\n",
      "2020-02-24 02:34:38 Training - Downloading the training image...\n",
      "2020-02-24 02:35:08 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:09,070 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:09,074 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:09,087 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:12,105 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:12,395 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:12,395 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:12,395 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:12,395 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpxfmevgc3/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=17835 sha256=2e88e8d3c0da403e27c6f6be2b594cb8d00532966fc52e35e19fd64d343d695e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yvinzzd3/wheels/2e/ea/e2/1887a74b7e2489869ebc73892c61f120d984ed2d28eec55adf\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:14,599 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:14,615 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:14,630 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:14,642 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input_dim\": 46,\n",
      "        \"hidden_dim\": 20,\n",
      "        \"epochs\": 100,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-02-24-02-32-12-040\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-165829362107/pytorch-training-2020-02-24-02-32-12-040/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":100,\"hidden_dim\":20,\"input_dim\":46,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-165829362107/pytorch-training-2020-02-24-02-32-12-040/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":100,\"hidden_dim\":20,\"input_dim\":46,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-02-24-02-32-12-040\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-165829362107/pytorch-training-2020-02-24-02-32-12-040/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"100\",\"--hidden_dim\",\"20\",\"--input_dim\",\"46\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_DIM=46\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=20\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 100 --hidden_dim 20 --input_dim 46 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mGet data loader.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/utils/smdebug.py:46: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-02-24 02:35:16.915 algo-1:43 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "  return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2020-02-24 02:35:16.915 algo-1:43 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/utils/smdebug.py:46: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-02-24 02:35:16.915 algo-1:43 INFO hook.py:197] Saving to /opt/ml/output/tensors\n",
      "  return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2020-02-24 02:35:16.916 algo-1:43 INFO hook.py:326] Monitoring the collections: losses\u001b[0m\n",
      "\n",
      "2020-02-24 02:35:41 Uploading - Uploading generated training model\n",
      "2020-02-24 02:35:41 Completed - Training job completed\n",
      "\u001b[34mEpoch: 1, Loss: 0.0032732226818828194\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.0011336126154867197\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.0007364468364164967\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.0006343874252210794\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.000591113973562394\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.0005862854247397715\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.0005584296986026774\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.0005646885844974101\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.0005407506510946956\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.0005289706402408863\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.0005090871164804522\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.000502492145725145\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.0004947624699773521\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.0004808006232258666\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.0004739223477372434\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.0004699763379573018\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.0004650570425093809\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.0004522534463004294\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.00044366232847978335\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.0004379380074114482\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.000434413556693912\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.0004271899644774032\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.0004250337616681601\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.00041964990922486214\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.00041263075620394596\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.00041195280512814253\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.00041051535928008064\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.00040823965030016774\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.0004048275696373876\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.0004049044286644361\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.0004034864396640897\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.0004000972246351673\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.0004002906441173488\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.00039955516430464655\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.00039778275547150497\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.0003963136464748955\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.00039359827215693343\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.0003962560009368286\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.00039406287672163944\u001b[0m\n",
      "\u001b[34m2020-02-24 02:35:29,216 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.00039543411251295106\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.00039583978341948807\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.00039532902370741465\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.0003956134432056305\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.00039675965286512633\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.00039741862879468084\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.00039785459000885373\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.0003966295215363833\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.00039481286132120823\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.00039271411652876077\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.0003928671359806851\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.0003925222425812425\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.0003920911833781495\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.0003920064262439899\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.0003922703958916386\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.0003926646373160607\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.00039471359587244507\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.0003982830803028209\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.0004015433610082696\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.0003995661178178676\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.00039233049546689443\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.0003900418840644169\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.00038899183428756345\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.0003883120028728048\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.00038785300917383705\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.0003874961414773927\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.0003872578608107605\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.00038710326429502334\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.00038671310600572423\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.0003865340585793037\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.00038633297332456675\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.0003861897949911619\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.00038608451838874976\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.0003859363682060961\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.0003857692053398668\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.000385903494051573\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.00038566382654332273\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.00038568546320179434\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.00038539663993023254\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.0003856012819155832\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.0003853642261453911\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.00038538317334534827\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.00038530037790857904\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.00038521506344709036\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.000385212240926745\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.00038514455897684183\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.0003851696777873616\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.000385076141438648\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.00038506344676672154\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.00038500789190893005\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.0003849713215679389\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.0003848959951221442\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.0003848425478667416\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.0003848170724791778\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.000384794136566184\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.0003847127685400086\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.00038475992666710886\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.00038468989618140216\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.00038463935297014274\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.0003845666190803361\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.0003845392712361045\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m[2020-02-24 02:35:29.046 algo-1:43 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "Training seconds: 90\n",
      "Billable seconds: 90\n",
      "CPU times: user 474 ms, sys: 34 ms, total: 508 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='source_simpleNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 326 ms, sys: 39.9 ms, total: 366 ms\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(pd.read_csv(\"data/val.csv\"))\n",
    "\n",
    "X_test = input_data[:, 1:]\n",
    "y_test = input_data[:, 0]\n",
    "\n",
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4779270633397313\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "y_test = y_test.reshape(y_pred.shape[0])\n",
    "\n",
    "accuracy = ( np.logical_or( np.logical_and(y_pred >= 0, y_test >= 0),\n",
    "                            np.logical_and(y_pred < 0, y_test < 0) ) ).sum() / len(y_test)\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test, y_pred, ls=' ', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "As we can see, our model successfully predicts 50.05% of the stock price movements, which is barely equal to the random walk ...\n",
    "\n",
    "Is it because the model too simple? Let me try in Step 3 with a better LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9d51d1652315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# delete the predictor endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
