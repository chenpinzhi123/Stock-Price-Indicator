{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Train the model\n",
    "\n",
    "Using the data created from Step 1, here we are going to build a simple benchmark model (simple neural network) to evaluate the stock return predictability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# default S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data' # the folder we will use for storing data\n",
    "name = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-1-165829362107/stock-price-predictor\n"
     ]
    }
   ],
   "source": [
    "# specify where to upload in S3\n",
    "prefix = 'stock-price-predictor'\n",
    "\n",
    "# upload to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock-price-predictor/data.csv\n",
      "stock-price-predictor/raw/sample-ff5.csv\n",
      "stock-price-predictor/raw/sample-fred.csv\n",
      "stock-price-predictor/raw/sample-stocks.csv\n",
      "stock-price-predictor/test.csv\n",
      "stock-price-predictor/train.csv\n"
     ]
    }
   ],
   "source": [
    "# iterate through S3 objects and print contents\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "     print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn.functional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m#\"\"\"\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mSimpleNet\u001b[39;49;00m(nn.Module):\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_dim, hidden_dim, output_dim):\n",
      "        \u001b[33m'''Defines layers of a neural network.\u001b[39;49;00m\n",
      "\u001b[33m           :param input_dim: Number of input features\u001b[39;49;00m\n",
      "\u001b[33m           :param hidden_dim: Size of hidden layer(s)\u001b[39;49;00m\n",
      "\u001b[33m           :param output_dim: Number of outputs\u001b[39;49;00m\n",
      "\u001b[33m         '''\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(SimpleNet, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "\n",
      "        \u001b[37m# defining 2 linear layers\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(input_dim, hidden_dim)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(hidden_dim, output_dim)\n",
      "        \u001b[36mself\u001b[39;49;00m.drop = nn.Dropout(\u001b[34m0.1\u001b[39;49;00m)\n",
      "        \u001b[37m# NO sigmoid layer\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        \u001b[33m'''Feedforward behavior of the net.\u001b[39;49;00m\n",
      "\u001b[33m           :param x: A batch of input features\u001b[39;49;00m\n",
      "\u001b[33m           :return: A single, sigmoid activated value\u001b[39;49;00m\n",
      "\u001b[33m        '''\u001b[39;49;00m\n",
      "        out = \u001b[36mself\u001b[39;49;00m.fc1(x)\n",
      "        \u001b[37m# out = F.relu(out)  # activation on hidden layer\u001b[39;49;00m\n",
      "\n",
      "        out = \u001b[36mself\u001b[39;49;00m.sig(out)\n",
      "        \u001b[37m# convert to from -1 to 1\u001b[39;49;00m\n",
      "        out = \u001b[34m2\u001b[39;49;00m * out - \u001b[34m1\u001b[39;49;00m\n",
      "\n",
      "        out = \u001b[36mself\u001b[39;49;00m.drop(out)\n",
      "        out = \u001b[36mself\u001b[39;49;00m.fc2(out)\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m out\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_simpleNet/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function  \u001b[37m# future proof\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# pytorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.optim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.utils.data\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# import model\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SimpleNet\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\n",
      "    model_info = {}\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = torch.load(f)\n",
      "\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\n",
      "\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model = SimpleNet(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33minput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                      model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                      model_info[\u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Load the stored model parameters.\u001b[39;49;00m\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\n",
      "\n",
      "\n",
      "\u001b[37m# Load the training data from a csv file\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_loader\u001b[39;49;00m(batch_size, data_dir):\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet data loader.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# read in csv file\u001b[39;49;00m\n",
      "    train_data = pd.read_csv(os.path.join(data_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[36mNone\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# labels are first column\u001b[39;49;00m\n",
      "    train_y = torch.from_numpy(train_data[[\u001b[34m0\u001b[39;49;00m]].values).float().squeeze()\n",
      "    \u001b[37m# features are the rest\u001b[39;49;00m\n",
      "    train_x = torch.from_numpy(train_data.drop([\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values).float()\n",
      "\n",
      "    \u001b[37m# create dataset\u001b[39;49;00m\n",
      "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
      "\n",
      "\n",
      "\u001b[37m# Provided train function\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model, train_loader, epochs, optimizer, criterion, device):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    This is the training method that is called by the PyTorch training script. The parameters\u001b[39;49;00m\n",
      "\u001b[33m    passed are as follows:\u001b[39;49;00m\n",
      "\u001b[33m    model        - The PyTorch model that we wish to train.\u001b[39;49;00m\n",
      "\u001b[33m    train_loader - The PyTorch DataLoader that should be used during training.\u001b[39;49;00m\n",
      "\u001b[33m    epochs       - The total number of epochs to train for.\u001b[39;49;00m\n",
      "\u001b[33m    optimizer    - The optimizer to use during training.\u001b[39;49;00m\n",
      "\u001b[33m    criterion    - The loss function used for training.\u001b[39;49;00m\n",
      "\u001b[33m    device       - Where the model and data should be loaded (gpu or cpu).\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train()\n",
      "        total_loss = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\n",
      "            \u001b[37m# prep data\u001b[39;49;00m\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            optimizer.zero_grad()  \u001b[37m# zero accumulated gradients\u001b[39;49;00m\n",
      "            \u001b[37m# get output of SimpleNet\u001b[39;49;00m\n",
      "            output = model(data)\n",
      "            \u001b[37m# calculate loss and perform backprop\u001b[39;49;00m\n",
      "            loss = criterion(output, target)\n",
      "            loss.backward(retain_graph=\u001b[36mTrue\u001b[39;49;00m)\n",
      "            \u001b[37m# loss.backward()\u001b[39;49;00m\n",
      "            optimizer.step()\n",
      "\n",
      "            total_loss += loss.item()\n",
      "\n",
      "        \u001b[37m# print loss stats\u001b[39;49;00m\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: {}, Loss: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch, total_loss / \u001b[36mlen\u001b[39;49;00m(train_loader)))\n",
      "\n",
      "    \u001b[37m# save trained model, after all epochs\u001b[39;49;00m\n",
      "    save_model(model, args.model_dir)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[37m# Provided model saving functions\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[37m# save state dictionary\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model_params\u001b[39;49;00m(model, model_dir):\n",
      "    model_info_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = {\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33minput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.input_dim,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.hidden_dim,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.output_dim\n",
      "        }\n",
      "        torch.save(model_info, f)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Training Parameters, given\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.001\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 0.001)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10000\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Model parameters\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--input_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m46\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of input features to model (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mhidden dim of model (default: 20)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mOUT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33moutput dim of model (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\n",
      "    \u001b[34mif\u001b[39;49;00m torch.cuda.is_available():\n",
      "        torch.cuda.manual_seed(args.seed)\n",
      "\n",
      "    \u001b[37m# get train loader\u001b[39;49;00m\n",
      "    train_loader = _get_train_loader(args.batch_size, args.data_dir)  \u001b[37m# data_dir from above..\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# To get params from the parser, call args.argument_name, ex. args.epochs or ards.hidden_dim\u001b[39;49;00m\n",
      "    \u001b[37m# Don't forget to move your model .to(device) to move to GPU , if appropriate\u001b[39;49;00m\n",
      "    model = SimpleNet(args.input_dim, args.hidden_dim, args.output_dim).to(device)\n",
      "\n",
      "    \u001b[37m# Given: save the parameters used to construct the model\u001b[39;49;00m\n",
      "    save_model_params(model, args.model_dir)\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
      "    criterion = nn.MSELoss()\n",
      "\n",
      "    \u001b[37m# Trains the model (given line of code, which calls the above training function)\u001b[39;49;00m\n",
      "    \u001b[37m# This function *also* saves the model state dictionary\u001b[39;49;00m\n",
      "    train(model, train_loader, args.epochs, optimizer, criterion, device)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_simpleNet/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "# prefix is specified above\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='source_simpleNet', # this should be just \"source\" for your code\n",
    "                    role=role,\n",
    "                    framework_version='1.3.1',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'input_dim': 46,  # num of features\n",
    "                        'hidden_dim': 20,\n",
    "                        'output_dim': 1,\n",
    "                        'epochs': 100 # could change to higher\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-20 06:08:15 Starting - Starting the training job...\n",
      "2020-02-20 06:08:16 Starting - Launching requested ML instances.........\n",
      "2020-02-20 06:09:47 Starting - Preparing the instances for training......\n",
      "2020-02-20 06:10:47 Downloading - Downloading input data...\n",
      "2020-02-20 06:11:41 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:43,035 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:43,037 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:43,049 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:46,077 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:46,455 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:46,455 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:46,455 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:46,456 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpr5evkv4z/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=17915 sha256=b8ecfaf5a4977cffa12286d30caf90576d03bb53af3b035c4495527545595017\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cbrzpntq/wheels/a1/37/67/b79fb6bca59717fac41abd119c74c357cad8e90260eec91fad\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:48,532 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:48,546 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:48,560 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-02-20 06:11:48,571 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input_dim\": 46,\n",
      "        \"hidden_dim\": 20,\n",
      "        \"epochs\": 100,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-02-20-06-08-14-829\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-165829362107/pytorch-training-2020-02-20-06-08-14-829/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":100,\"hidden_dim\":20,\"input_dim\":46,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-165829362107/pytorch-training-2020-02-20-06-08-14-829/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":100,\"hidden_dim\":20,\"input_dim\":46,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-02-20-06-08-14-829\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-165829362107/pytorch-training-2020-02-20-06-08-14-829/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"100\",\"--hidden_dim\",\"20\",\"--input_dim\",\"46\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_DIM=46\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=20\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 100 --hidden_dim 20 --input_dim 46 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mGet data loader.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/utils/smdebug.py:46: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-02-20 06:11:50.858 algo-1:45 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "  return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2020-02-20 06:11:50.859 algo-1:45 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/utils/smdebug.py:46: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-02-20 06:11:50.859 algo-1:45 INFO hook.py:197] Saving to /opt/ml/output/tensors\n",
      "  return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2020-02-20 06:11:50.859 algo-1:45 INFO hook.py:326] Monitoring the collections: losses\u001b[0m\n",
      "\n",
      "2020-02-20 06:12:10 Uploading - Uploading generated training model\n",
      "2020-02-20 06:12:10 Completed - Training job completed\n",
      "\u001b[34mEpoch: 1, Loss: 0.0032732226818828194\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.0011336126154867197\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.0007364468364164967\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.0006343874252210794\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.000591113973562394\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.0005862854247397715\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.0005584296986026774\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.0005646885844974101\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.0005407506510946956\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.0005289706402408863\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.0005090871164804522\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.000502492145725145\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.0004947624699773521\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.0004808006232258666\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.0004739223477372434\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.0004699763379573018\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.0004650570425093809\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.0004522534463004294\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.00044366232847978335\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.0004379380074114482\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.000434413556693912\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.0004271899644774032\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.0004250337616681601\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.00041964990922486214\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.00041263075620394596\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.00041195280512814253\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.00041051535928008064\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.00040823965030016774\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.0004048275696373876\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.0004049044286644361\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.0004034864396640897\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.0004000972246351673\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.0004002906441173488\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.00039955516430464655\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.00039778275547150497\u001b[0m\n",
      "\u001b[34m2020-02-20 06:12:02,394 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.0003963136464748955\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.00039359827215693343\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.0003962560009368286\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.00039406287672163944\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.00039543411251295106\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.00039583978341948807\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.00039532902370741465\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.0003956134432056305\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.00039675965286512633\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.00039741862879468084\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.00039785459000885373\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.0003966295215363833\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.00039481286132120823\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.00039271411652876077\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.0003928671359806851\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.0003925222425812425\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.0003920911833781495\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.0003920064262439899\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.0003922703958916386\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.0003926646373160607\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.00039471359587244507\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.0003982830803028209\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.0004015433610082696\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.0003995661178178676\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.00039233049546689443\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.0003900418840644169\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.00038899183428756345\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.0003883120028728048\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.00038785300917383705\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.0003874961414773927\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.0003872578608107605\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.00038710326429502334\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.00038671310600572423\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.0003865340585793037\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.00038633297332456675\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.0003861897949911619\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.00038608451838874976\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.0003859363682060961\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.0003857692053398668\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.000385903494051573\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.00038566382654332273\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.00038568546320179434\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.00038539663993023254\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.0003856012819155832\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.0003853642261453911\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.00038538317334534827\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.00038530037790857904\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.00038521506344709036\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.000385212240926745\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.00038514455897684183\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.0003851696777873616\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.000385076141438648\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.00038506344676672154\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.00038500789190893005\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.0003849713215679389\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.0003848959951221442\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.0003848425478667416\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.0003848170724791778\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.000384794136566184\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.0003847127685400086\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.00038475992666710886\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.00038468989618140216\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.00038463935297014274\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.0003845666190803361\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.0003845392712361045\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m[2020-02-20 06:12:02.259 algo-1:45 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "Training seconds: 83\n",
      "Billable seconds: 83\n",
      "CPU times: user 523 ms, sys: 24.9 ms, total: 547 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='source_simpleNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 331 ms, sys: 27.7 ms, total: 359 ms\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(pd.read_csv(\"data/test.csv\"))\n",
    "\n",
    "X_test = input_data[:, 1:]\n",
    "y_test = input_data[:, 0]\n",
    "\n",
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5004793863854267\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "y_test = y_test.reshape(y_pred.shape[0])\n",
    "\n",
    "accuracy = ( np.logical_or( np.logical_and(y_pred >= 0, y_test >= 0),\n",
    "                            np.logical_and(y_pred < 0, y_test < 0) ) ).sum() / len(y_test)\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test, y_pred, ls=' ', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "As we can see, our model successfully predicts 50.05% of the stock price movements, which is barely equal to the random walk ...\n",
    "\n",
    "Is it because the model too simple? Let me try in Step 3 with a better LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9d51d1652315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# delete the predictor endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
